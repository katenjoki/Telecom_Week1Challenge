{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_column', None)\n",
    "pd.set_option('display.float_format',lambda x:'%5f'%x)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bearer Id</th>\n",
       "      <th>Start</th>\n",
       "      <th>Start ms</th>\n",
       "      <th>End</th>\n",
       "      <th>End ms</th>\n",
       "      <th>Dur. (ms)</th>\n",
       "      <th>IMSI</th>\n",
       "      <th>MSISDN/Number</th>\n",
       "      <th>IMEI</th>\n",
       "      <th>Last Location Name</th>\n",
       "      <th>Avg RTT DL (ms)</th>\n",
       "      <th>Avg RTT UL (ms)</th>\n",
       "      <th>Avg Bearer TP DL (kbps)</th>\n",
       "      <th>Avg Bearer TP UL (kbps)</th>\n",
       "      <th>TCP DL Retrans. Vol (Bytes)</th>\n",
       "      <th>TCP UL Retrans. Vol (Bytes)</th>\n",
       "      <th>DL TP &lt; 50 Kbps (%)</th>\n",
       "      <th>50 Kbps &lt; DL TP &lt; 250 Kbps (%)</th>\n",
       "      <th>250 Kbps &lt; DL TP &lt; 1 Mbps (%)</th>\n",
       "      <th>DL TP &gt; 1 Mbps (%)</th>\n",
       "      <th>UL TP &lt; 10 Kbps (%)</th>\n",
       "      <th>10 Kbps &lt; UL TP &lt; 50 Kbps (%)</th>\n",
       "      <th>50 Kbps &lt; UL TP &lt; 300 Kbps (%)</th>\n",
       "      <th>UL TP &gt; 300 Kbps (%)</th>\n",
       "      <th>HTTP DL (Bytes)</th>\n",
       "      <th>HTTP UL (Bytes)</th>\n",
       "      <th>Activity Duration DL (ms)</th>\n",
       "      <th>Activity Duration UL (ms)</th>\n",
       "      <th>Dur. (ms).1</th>\n",
       "      <th>Handset Manufacturer</th>\n",
       "      <th>Handset Type</th>\n",
       "      <th>Nb of sec with 125000B &lt; Vol DL</th>\n",
       "      <th>Nb of sec with 1250B &lt; Vol UL &lt; 6250B</th>\n",
       "      <th>Nb of sec with 31250B &lt; Vol DL &lt; 125000B</th>\n",
       "      <th>Nb of sec with 37500B &lt; Vol UL</th>\n",
       "      <th>Nb of sec with 6250B &lt; Vol DL &lt; 31250B</th>\n",
       "      <th>Nb of sec with 6250B &lt; Vol UL &lt; 37500B</th>\n",
       "      <th>Nb of sec with Vol DL &lt; 6250B</th>\n",
       "      <th>Nb of sec with Vol UL &lt; 1250B</th>\n",
       "      <th>Social Media DL (Bytes)</th>\n",
       "      <th>Social Media UL (Bytes)</th>\n",
       "      <th>Google DL (Bytes)</th>\n",
       "      <th>Google UL (Bytes)</th>\n",
       "      <th>Email DL (Bytes)</th>\n",
       "      <th>Email UL (Bytes)</th>\n",
       "      <th>Youtube DL (Bytes)</th>\n",
       "      <th>Youtube UL (Bytes)</th>\n",
       "      <th>Netflix DL (Bytes)</th>\n",
       "      <th>Netflix UL (Bytes)</th>\n",
       "      <th>Gaming DL (Bytes)</th>\n",
       "      <th>Gaming UL (Bytes)</th>\n",
       "      <th>Other DL (Bytes)</th>\n",
       "      <th>Other UL (Bytes)</th>\n",
       "      <th>Total UL (Bytes)</th>\n",
       "      <th>Total DL (Bytes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13114483460844900352.000000</td>\n",
       "      <td>4/4/2019 12:01</td>\n",
       "      <td>770.000000</td>\n",
       "      <td>4/25/2019 14:35</td>\n",
       "      <td>662.000000</td>\n",
       "      <td>1823652.000000</td>\n",
       "      <td>208201448079117.000000</td>\n",
       "      <td>33664962239.000000</td>\n",
       "      <td>35521209507511.000000</td>\n",
       "      <td>9.16456699548519E+015</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37624.000000</td>\n",
       "      <td>38787.000000</td>\n",
       "      <td>1823652892.000000</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>Samsung Galaxy A5 Sm-A520F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>1545765.000000</td>\n",
       "      <td>24420.000000</td>\n",
       "      <td>1634479.000000</td>\n",
       "      <td>1271433.000000</td>\n",
       "      <td>3563542.000000</td>\n",
       "      <td>137762.000000</td>\n",
       "      <td>15854611.000000</td>\n",
       "      <td>2501332.000000</td>\n",
       "      <td>8198936.000000</td>\n",
       "      <td>9656251.000000</td>\n",
       "      <td>278082303.000000</td>\n",
       "      <td>14344150.000000</td>\n",
       "      <td>171744450.000000</td>\n",
       "      <td>8814393.000000</td>\n",
       "      <td>36749741.000000</td>\n",
       "      <td>308879636.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13114483482878900224.000000</td>\n",
       "      <td>4/9/2019 13:04</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>4/25/2019 8:15</td>\n",
       "      <td>606.000000</td>\n",
       "      <td>1365104.000000</td>\n",
       "      <td>208201909211140.000000</td>\n",
       "      <td>33681854413.000000</td>\n",
       "      <td>35794009006359.000000</td>\n",
       "      <td>L77566A</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>3560.000000</td>\n",
       "      <td>1365104371.000000</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>Samsung Galaxy J5 (Sm-J530)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>971.000000</td>\n",
       "      <td>1022.000000</td>\n",
       "      <td>1926113.000000</td>\n",
       "      <td>7165.000000</td>\n",
       "      <td>3493924.000000</td>\n",
       "      <td>920172.000000</td>\n",
       "      <td>629046.000000</td>\n",
       "      <td>308339.000000</td>\n",
       "      <td>20247395.000000</td>\n",
       "      <td>19111729.000000</td>\n",
       "      <td>18338413.000000</td>\n",
       "      <td>17227132.000000</td>\n",
       "      <td>608750074.000000</td>\n",
       "      <td>1170709.000000</td>\n",
       "      <td>526904238.000000</td>\n",
       "      <td>15055145.000000</td>\n",
       "      <td>53800391.000000</td>\n",
       "      <td>653384965.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13114483484080500736.000000</td>\n",
       "      <td>4/9/2019 17:42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4/25/2019 11:58</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>1361762.000000</td>\n",
       "      <td>208200314458056.000000</td>\n",
       "      <td>33760627129.000000</td>\n",
       "      <td>35281510359387.000000</td>\n",
       "      <td>D42335A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1361762651.000000</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>Samsung Galaxy A8 (2018)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>751.000000</td>\n",
       "      <td>695.000000</td>\n",
       "      <td>1684053.000000</td>\n",
       "      <td>42224.000000</td>\n",
       "      <td>8535055.000000</td>\n",
       "      <td>1694064.000000</td>\n",
       "      <td>2690151.000000</td>\n",
       "      <td>672973.000000</td>\n",
       "      <td>19725661.000000</td>\n",
       "      <td>14699576.000000</td>\n",
       "      <td>17587794.000000</td>\n",
       "      <td>6163408.000000</td>\n",
       "      <td>229584621.000000</td>\n",
       "      <td>395630.000000</td>\n",
       "      <td>410692588.000000</td>\n",
       "      <td>4215763.000000</td>\n",
       "      <td>27883638.000000</td>\n",
       "      <td>279807335.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13114483485442799616.000000</td>\n",
       "      <td>4/10/2019 0:31</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>4/25/2019 7:36</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>1321509.000000</td>\n",
       "      <td>208201402342131.000000</td>\n",
       "      <td>33750343200.000000</td>\n",
       "      <td>35356610164913.000000</td>\n",
       "      <td>T21824A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3330.000000</td>\n",
       "      <td>37882.000000</td>\n",
       "      <td>1321509685.000000</td>\n",
       "      <td>undefined</td>\n",
       "      <td>undefined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>644121.000000</td>\n",
       "      <td>13372.000000</td>\n",
       "      <td>9023734.000000</td>\n",
       "      <td>2788027.000000</td>\n",
       "      <td>1439754.000000</td>\n",
       "      <td>631229.000000</td>\n",
       "      <td>21388122.000000</td>\n",
       "      <td>15146643.000000</td>\n",
       "      <td>13994646.000000</td>\n",
       "      <td>1097942.000000</td>\n",
       "      <td>799538153.000000</td>\n",
       "      <td>10849722.000000</td>\n",
       "      <td>749039933.000000</td>\n",
       "      <td>12797283.000000</td>\n",
       "      <td>43324218.000000</td>\n",
       "      <td>846028530.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13114483499480700928.000000</td>\n",
       "      <td>4/12/2019 20:10</td>\n",
       "      <td>565.000000</td>\n",
       "      <td>4/25/2019 10:40</td>\n",
       "      <td>954.000000</td>\n",
       "      <td>1089009.000000</td>\n",
       "      <td>208201401415120.000000</td>\n",
       "      <td>33699795932.000000</td>\n",
       "      <td>35407009745539.000000</td>\n",
       "      <td>D88865A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1089009389.000000</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>Samsung Sm-G390F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>862600.000000</td>\n",
       "      <td>50188.000000</td>\n",
       "      <td>6248284.000000</td>\n",
       "      <td>1500559.000000</td>\n",
       "      <td>1936496.000000</td>\n",
       "      <td>173853.000000</td>\n",
       "      <td>15259380.000000</td>\n",
       "      <td>18962873.000000</td>\n",
       "      <td>17124581.000000</td>\n",
       "      <td>415218.000000</td>\n",
       "      <td>527707248.000000</td>\n",
       "      <td>3529801.000000</td>\n",
       "      <td>550709500.000000</td>\n",
       "      <td>13910322.000000</td>\n",
       "      <td>38542814.000000</td>\n",
       "      <td>569138589.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Bearer Id            Start   Start ms              End  \\\n",
       "0 13114483460844900352.000000   4/4/2019 12:01 770.000000  4/25/2019 14:35   \n",
       "1 13114483482878900224.000000   4/9/2019 13:04 235.000000   4/25/2019 8:15   \n",
       "2 13114483484080500736.000000   4/9/2019 17:42   1.000000  4/25/2019 11:58   \n",
       "3 13114483485442799616.000000   4/10/2019 0:31 486.000000   4/25/2019 7:36   \n",
       "4 13114483499480700928.000000  4/12/2019 20:10 565.000000  4/25/2019 10:40   \n",
       "\n",
       "      End ms      Dur. (ms)                   IMSI      MSISDN/Number  \\\n",
       "0 662.000000 1823652.000000 208201448079117.000000 33664962239.000000   \n",
       "1 606.000000 1365104.000000 208201909211140.000000 33681854413.000000   \n",
       "2 652.000000 1361762.000000 208200314458056.000000 33760627129.000000   \n",
       "3 171.000000 1321509.000000 208201402342131.000000 33750343200.000000   \n",
       "4 954.000000 1089009.000000 208201401415120.000000 33699795932.000000   \n",
       "\n",
       "                   IMEI     Last Location Name  Avg RTT DL (ms)  \\\n",
       "0 35521209507511.000000  9.16456699548519E+015        42.000000   \n",
       "1 35794009006359.000000                L77566A        65.000000   \n",
       "2 35281510359387.000000                D42335A              NaN   \n",
       "3 35356610164913.000000                T21824A              NaN   \n",
       "4 35407009745539.000000                D88865A              NaN   \n",
       "\n",
       "   Avg RTT UL (ms)  Avg Bearer TP DL (kbps)  Avg Bearer TP UL (kbps)  \\\n",
       "0         5.000000                23.000000                44.000000   \n",
       "1         5.000000                16.000000                26.000000   \n",
       "2              NaN                 6.000000                 9.000000   \n",
       "3              NaN                44.000000                44.000000   \n",
       "4              NaN                 6.000000                 9.000000   \n",
       "\n",
       "   TCP DL Retrans. Vol (Bytes)  TCP UL Retrans. Vol (Bytes)  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2                          NaN                          NaN   \n",
       "3                          NaN                          NaN   \n",
       "4                          NaN                          NaN   \n",
       "\n",
       "   DL TP < 50 Kbps (%)  50 Kbps < DL TP < 250 Kbps (%)  \\\n",
       "0           100.000000                        0.000000   \n",
       "1           100.000000                        0.000000   \n",
       "2           100.000000                        0.000000   \n",
       "3           100.000000                        0.000000   \n",
       "4           100.000000                        0.000000   \n",
       "\n",
       "   250 Kbps < DL TP < 1 Mbps (%)  DL TP > 1 Mbps (%)  UL TP < 10 Kbps (%)  \\\n",
       "0                       0.000000            0.000000           100.000000   \n",
       "1                       0.000000            0.000000           100.000000   \n",
       "2                       0.000000            0.000000           100.000000   \n",
       "3                       0.000000            0.000000           100.000000   \n",
       "4                       0.000000            0.000000           100.000000   \n",
       "\n",
       "   10 Kbps < UL TP < 50 Kbps (%)  50 Kbps < UL TP < 300 Kbps (%)  \\\n",
       "0                       0.000000                        0.000000   \n",
       "1                       0.000000                        0.000000   \n",
       "2                       0.000000                        0.000000   \n",
       "3                       0.000000                        0.000000   \n",
       "4                       0.000000                        0.000000   \n",
       "\n",
       "   UL TP > 300 Kbps (%)  HTTP DL (Bytes)  HTTP UL (Bytes)  \\\n",
       "0              0.000000              NaN              NaN   \n",
       "1              0.000000              NaN              NaN   \n",
       "2              0.000000              NaN              NaN   \n",
       "3              0.000000              NaN              NaN   \n",
       "4              0.000000              NaN              NaN   \n",
       "\n",
       "   Activity Duration DL (ms)  Activity Duration UL (ms)       Dur. (ms).1  \\\n",
       "0               37624.000000               38787.000000 1823652892.000000   \n",
       "1                 168.000000                3560.000000 1365104371.000000   \n",
       "2                   0.000000                   0.000000 1361762651.000000   \n",
       "3                3330.000000               37882.000000 1321509685.000000   \n",
       "4                   0.000000                   0.000000 1089009389.000000   \n",
       "\n",
       "  Handset Manufacturer                 Handset Type  \\\n",
       "0              Samsung   Samsung Galaxy A5 Sm-A520F   \n",
       "1              Samsung  Samsung Galaxy J5 (Sm-J530)   \n",
       "2              Samsung     Samsung Galaxy A8 (2018)   \n",
       "3            undefined                    undefined   \n",
       "4              Samsung             Samsung Sm-G390F   \n",
       "\n",
       "   Nb of sec with 125000B < Vol DL  Nb of sec with 1250B < Vol UL < 6250B  \\\n",
       "0                              NaN                                    NaN   \n",
       "1                              NaN                                    NaN   \n",
       "2                              NaN                                    NaN   \n",
       "3                              NaN                                    NaN   \n",
       "4                              NaN                                    NaN   \n",
       "\n",
       "   Nb of sec with 31250B < Vol DL < 125000B  Nb of sec with 37500B < Vol UL  \\\n",
       "0                                       NaN                             NaN   \n",
       "1                                       NaN                             NaN   \n",
       "2                                       NaN                             NaN   \n",
       "3                                       NaN                             NaN   \n",
       "4                                       NaN                             NaN   \n",
       "\n",
       "   Nb of sec with 6250B < Vol DL < 31250B  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "\n",
       "   Nb of sec with 6250B < Vol UL < 37500B  Nb of sec with Vol DL < 6250B  \\\n",
       "0                                     NaN                     213.000000   \n",
       "1                                     NaN                     971.000000   \n",
       "2                                     NaN                     751.000000   \n",
       "3                                     NaN                      17.000000   \n",
       "4                                     NaN                     607.000000   \n",
       "\n",
       "   Nb of sec with Vol UL < 1250B  Social Media DL (Bytes)  \\\n",
       "0                     214.000000           1545765.000000   \n",
       "1                    1022.000000           1926113.000000   \n",
       "2                     695.000000           1684053.000000   \n",
       "3                     207.000000            644121.000000   \n",
       "4                     604.000000            862600.000000   \n",
       "\n",
       "   Social Media UL (Bytes)  Google DL (Bytes)  Google UL (Bytes)  \\\n",
       "0             24420.000000     1634479.000000     1271433.000000   \n",
       "1              7165.000000     3493924.000000      920172.000000   \n",
       "2             42224.000000     8535055.000000     1694064.000000   \n",
       "3             13372.000000     9023734.000000     2788027.000000   \n",
       "4             50188.000000     6248284.000000     1500559.000000   \n",
       "\n",
       "   Email DL (Bytes)  Email UL (Bytes)  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
       "0    3563542.000000     137762.000000     15854611.000000      2501332.000000   \n",
       "1     629046.000000     308339.000000     20247395.000000     19111729.000000   \n",
       "2    2690151.000000     672973.000000     19725661.000000     14699576.000000   \n",
       "3    1439754.000000     631229.000000     21388122.000000     15146643.000000   \n",
       "4    1936496.000000     173853.000000     15259380.000000     18962873.000000   \n",
       "\n",
       "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
       "0      8198936.000000      9656251.000000   278082303.000000   \n",
       "1     18338413.000000     17227132.000000   608750074.000000   \n",
       "2     17587794.000000      6163408.000000   229584621.000000   \n",
       "3     13994646.000000      1097942.000000   799538153.000000   \n",
       "4     17124581.000000       415218.000000   527707248.000000   \n",
       "\n",
       "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
       "0    14344150.000000  171744450.000000    8814393.000000   36749741.000000   \n",
       "1     1170709.000000  526904238.000000   15055145.000000   53800391.000000   \n",
       "2      395630.000000  410692588.000000    4215763.000000   27883638.000000   \n",
       "3    10849722.000000  749039933.000000   12797283.000000   43324218.000000   \n",
       "4     3529801.000000  550709500.000000   13910322.000000   38542814.000000   \n",
       "\n",
       "   Total DL (Bytes)  \n",
       "0  308879636.000000  \n",
       "1  653384965.000000  \n",
       "2  279807335.000000  \n",
       "3  846028530.000000  \n",
       "4  569138589.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/katenjoki/Telecom_Week1Challenge/main/OneDrive/Desktop/10Academy/Telecom_Week1Challenge/data/Week1_challenge_data_source(CSV).csv'\n",
    "data = pd.read_csv(url)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150001, 55)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150001 entries, 0 to 150000\n",
      "Data columns (total 55 columns):\n",
      " #   Column                                    Non-Null Count   Dtype  \n",
      "---  ------                                    --------------   -----  \n",
      " 0   Bearer Id                                 149010 non-null  float64\n",
      " 1   Start                                     150000 non-null  object \n",
      " 2   Start ms                                  150000 non-null  float64\n",
      " 3   End                                       150000 non-null  object \n",
      " 4   End ms                                    150000 non-null  float64\n",
      " 5   Dur. (ms)                                 150000 non-null  float64\n",
      " 6   IMSI                                      149431 non-null  float64\n",
      " 7   MSISDN/Number                             148935 non-null  float64\n",
      " 8   IMEI                                      149429 non-null  float64\n",
      " 9   Last Location Name                        148848 non-null  object \n",
      " 10  Avg RTT DL (ms)                           122172 non-null  float64\n",
      " 11  Avg RTT UL (ms)                           122189 non-null  float64\n",
      " 12  Avg Bearer TP DL (kbps)                   150000 non-null  float64\n",
      " 13  Avg Bearer TP UL (kbps)                   150000 non-null  float64\n",
      " 14  TCP DL Retrans. Vol (Bytes)               61855 non-null   float64\n",
      " 15  TCP UL Retrans. Vol (Bytes)               53352 non-null   float64\n",
      " 16  DL TP < 50 Kbps (%)                       149247 non-null  float64\n",
      " 17  50 Kbps < DL TP < 250 Kbps (%)            149247 non-null  float64\n",
      " 18  250 Kbps < DL TP < 1 Mbps (%)             149247 non-null  float64\n",
      " 19  DL TP > 1 Mbps (%)                        149247 non-null  float64\n",
      " 20  UL TP < 10 Kbps (%)                       149209 non-null  float64\n",
      " 21  10 Kbps < UL TP < 50 Kbps (%)             149209 non-null  float64\n",
      " 22  50 Kbps < UL TP < 300 Kbps (%)            149209 non-null  float64\n",
      " 23  UL TP > 300 Kbps (%)                      149209 non-null  float64\n",
      " 24  HTTP DL (Bytes)                           68527 non-null   float64\n",
      " 25  HTTP UL (Bytes)                           68191 non-null   float64\n",
      " 26  Activity Duration DL (ms)                 150000 non-null  float64\n",
      " 27  Activity Duration UL (ms)                 150000 non-null  float64\n",
      " 28  Dur. (ms).1                               150000 non-null  float64\n",
      " 29  Handset Manufacturer                      149429 non-null  object \n",
      " 30  Handset Type                              149429 non-null  object \n",
      " 31  Nb of sec with 125000B < Vol DL           52463 non-null   float64\n",
      " 32  Nb of sec with 1250B < Vol UL < 6250B     57107 non-null   float64\n",
      " 33  Nb of sec with 31250B < Vol DL < 125000B  56415 non-null   float64\n",
      " 34  Nb of sec with 37500B < Vol UL            19747 non-null   float64\n",
      " 35  Nb of sec with 6250B < Vol DL < 31250B    61684 non-null   float64\n",
      " 36  Nb of sec with 6250B < Vol UL < 37500B    38158 non-null   float64\n",
      " 37  Nb of sec with Vol DL < 6250B             149246 non-null  float64\n",
      " 38  Nb of sec with Vol UL < 1250B             149208 non-null  float64\n",
      " 39  Social Media DL (Bytes)                   150001 non-null  float64\n",
      " 40  Social Media UL (Bytes)                   150001 non-null  float64\n",
      " 41  Google DL (Bytes)                         150001 non-null  float64\n",
      " 42  Google UL (Bytes)                         150001 non-null  float64\n",
      " 43  Email DL (Bytes)                          150001 non-null  float64\n",
      " 44  Email UL (Bytes)                          150001 non-null  float64\n",
      " 45  Youtube DL (Bytes)                        150001 non-null  float64\n",
      " 46  Youtube UL (Bytes)                        150001 non-null  float64\n",
      " 47  Netflix DL (Bytes)                        150001 non-null  float64\n",
      " 48  Netflix UL (Bytes)                        150001 non-null  float64\n",
      " 49  Gaming DL (Bytes)                         150001 non-null  float64\n",
      " 50  Gaming UL (Bytes)                         150001 non-null  float64\n",
      " 51  Other DL (Bytes)                          150001 non-null  float64\n",
      " 52  Other UL (Bytes)                          150001 non-null  float64\n",
      " 53  Total UL (Bytes)                          150000 non-null  float64\n",
      " 54  Total DL (Bytes)                          150000 non-null  float64\n",
      "dtypes: float64(50), object(5)\n",
      "memory usage: 62.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-17 10:27:32.691 INFO    numexpr.utils: NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y = data['Gaming DL (Bytes)'] * data['Gaming UL (Bytes)']\n",
    "data['Nb of sec with 6250B < Vol DL < 31250B']=data['Nb of sec with 6250B < Vol DL < 31250B'].fillna(y)\n",
    "data['Nb of sec with 6250B < Vol DL < 31250B'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5,6,7,8,9,10]\n",
    "df = pd.DataFrame(x,columns=['numbers'])\n",
    "\n",
    "def map_num(num):\n",
    "    if num <= 3:\n",
    "        return 'less than 3'\n",
    "    elif num <6:\n",
    "        return 'less than 6 greater than 3'\n",
    "    else:\n",
    "        return 'less than 10'\n",
    "    \n",
    "df['rate'] = df['numbers'].apply(lambda num: map_num(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 3, 'c': 2, 'b': 2, 'e': 1, 'd': 1, 'f': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3,4,5,6,7,8,9,10]\n",
    "y = ['a','a','a','b','c','c','b','d','e','f']\n",
    "df = pd.DataFrame(x,columns=['numbers'])\n",
    "df['letters'] = y\n",
    "\n",
    "dff = dict(df['letters'].value_counts())\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2d3d3b581576>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Start ms'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_z' is not defined"
     ]
    }
   ],
   "source": [
    "data['Start ms'].fillna(mean_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(data['Nb of sec with 125000B < Vol DL'].dropna())\n",
    "y = sorted(x)\n",
    "y = y[:len(y)-10]\n",
    "\n",
    "y = sorted(y,ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task 1 : User Overview Analysis </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Data Cleaning </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.replace(' ','_')\n",
    "data.columns = data.columns.str.replace('/','_')\n",
    "data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dates to datetime\n",
    "data['Start_ms']=pd.to_datetime(data['Start_ms'])\n",
    "data['End_ms']=pd.to_datetime(data['End_ms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are rows where all column values are null\n",
    "check_null = data.columns.isnull().any()\n",
    "check_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% of null values\n",
    "def null_analysis(df):\n",
    "    total_values = np.product(df.shape)\n",
    "    total_null = (df.isnull().sum()).sum()\n",
    "    proportion_null = (total_null / total_values)*100\n",
    "    \n",
    "    print(\"The Telcommunication dataset has \",proportion_null,\"% null values.\")\n",
    "\n",
    "null_analysis(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding columns that have more than 30% of null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_per_column(df):\n",
    "    dataset = df.isnull().sum()\n",
    "    dataset = pd.DataFrame(dataset,columns=['null'])\n",
    "    dataset['%null'] = (dataset['null']/df.shape[0])*100\n",
    "    dataframe = dataset[dataset['%null']>=30]\n",
    "    print(dataframe)    \n",
    "    #print('\\n List of columns with more than 30% null values:\\n',dataframe.index.to_list())\n",
    "\n",
    "null_per_column(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns with more than 30% null values,apart from the TCP columns\n",
    "data=data.drop(['HTTP_DL_(Bytes)', 'HTTP_UL_(Bytes)', 'Nb_of_sec_with_125000B_<_Vol_DL', 'Nb_of_sec_with_1250B_<_Vol_UL_<_6250B', 'Nb_of_sec_with_31250B_<_Vol_DL_<_125000B', 'Nb_of_sec_with_37500B_<_Vol_UL', 'Nb_of_sec_with_6250B_<_Vol_DL_<_31250B', 'Nb_of_sec_with_6250B_<_Vol_UL_<_37500B'],axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Column Bearer Id has 991 null values, we drop these rows as the Bearer Id should be a unique identifier and we have a large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Bearer_Id'].notna()]\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null values for object types with mode\n",
    "def null_objects(df,column):\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "    return df[column]\n",
    "\n",
    "data['Last_Location_Name'] = null_objects(data,'Last_Location_Name')\n",
    "data['Handset_Manufacturer'] = null_objects(data,'Handset_Manufacturer')\n",
    "data['Handset_Type']= null_objects(data,'Handset_Type')\n",
    "\n",
    "#list of columns with null values,\n",
    "def null_values(df):\n",
    "    dataframe=df.isnull().sum()\n",
    "    dataframe=pd.DataFrame(dataframe,columns=['null'])\n",
    "    dataframe=dataframe[dataframe['null']>0]\n",
    "    print(dataframe.index.to_list())\n",
    "\n",
    "null_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check skewness\n",
    "data_test=data[['TCP_DL_Retrans._Vol_(Bytes)','TCP_UL_Retrans._Vol_(Bytes)','IMSI', 'MSISDN_Number', 'IMEI', 'Avg_RTT_DL_(ms)', 'Avg_RTT_UL_(ms)', 'DL_TP_<_50_Kbps_(%)', '50_Kbps_<_DL_TP_<_250_Kbps_(%)', '250_Kbps_<_DL_TP_<_1_Mbps_(%)', 'DL_TP_>_1_Mbps_(%)', 'UL_TP_<_10_Kbps_(%)', '10_Kbps_<_UL_TP_<_50_Kbps_(%)', '50_Kbps_<_UL_TP_<_300_Kbps_(%)', 'UL_TP_>_300_Kbps_(%)', 'Nb_of_sec_with_Vol_DL_<_6250B', 'Nb_of_sec_with_Vol_UL_<_1250B']]\n",
    "data_test.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since data is skewed we replace the null values with the median\n",
    "column_names = ['TCP_DL_Retrans._Vol_(Bytes)','TCP_UL_Retrans._Vol_(Bytes)','IMSI', 'MSISDN_Number', 'IMEI', 'Avg_RTT_DL_(ms)', 'Avg_RTT_UL_(ms)', 'DL_TP_<_50_Kbps_(%)', '50_Kbps_<_DL_TP_<_250_Kbps_(%)', '250_Kbps_<_DL_TP_<_1_Mbps_(%)', 'DL_TP_>_1_Mbps_(%)', 'UL_TP_<_10_Kbps_(%)', '10_Kbps_<_UL_TP_<_50_Kbps_(%)', '50_Kbps_<_UL_TP_<_300_Kbps_(%)', 'UL_TP_>_300_Kbps_(%)', 'Nb_of_sec_with_Vol_DL_<_6250B', 'Nb_of_sec_with_Vol_UL_<_1250B']\n",
    "\n",
    "for i in column_names:\n",
    "    data[i]=data[i].fillna(data[i].median())\n",
    "\n",
    "(data.isnull().sum()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize each engagement metric;user behavior can be tracked through the following applications:  Social Media, Google, Email, Youtube, Netflix, Gaming, Other.**\n",
    "**These variables will be used for k-means forecasting hence why we normalize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#columns = ['Social_Media_DL_(Bytes)','Social_Media_UL_(Bytes)', 'Google_DL_(Bytes)', 'Google_UL_(Bytes)','Email_DL_(Bytes)', 'Email_UL_(Bytes)', 'Youtube_DL_(Bytes)','Youtube_UL_(Bytes)', 'Netflix_DL_(Bytes)', 'Netflix_UL_(Bytes)',\n",
    " #      'Gaming_DL_(Bytes)', 'Gaming_UL_(Bytes)', 'Other_DL_(Bytes)','Other_UL_(Bytes)']\n",
    "\n",
    "#data[columns]=MinMaxScaler().fit_transform(data[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Function to determine top n entries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n(df,column,n):\n",
    "    top=df[column].value_counts().head(n)\n",
    "    return top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identifying the top 10 handsets used by the customers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n(data,'Handset_Type',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identifying the top 3 handset manufacturers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n(data,'Handset_Manufacturer',3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identifying the top 5 handsets per top 3 handset manufacturer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=data[['Handset_Manufacturer','Handset_Type']]\n",
    "manufacturers=top_n(data,'Handset_Manufacturer',3).index.to_list()\n",
    "dataframe = dataframe[dataframe['Handset_Manufacturer'].isin(manufacturers)]\n",
    "\n",
    "dataframe.groupby('Handset_Manufacturer').Handset_Type.value_counts().groupby(level=0,group_keys=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview of the users’ behavior on the applications**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_columns(df,col1,col2):\n",
    "    return df[col1]+df[col2]\n",
    "\n",
    "def avg_col(df,col1,col2):\n",
    "    return (df[col1]+df[col2])/2\n",
    "\n",
    "frame = pd.DataFrame(data,columns=['MSISDN_Number','Bearer_Id','Dur._(ms)','Handset_Type'])\n",
    "frame['Social_Media_Bytes']=sum_columns(data,'Social_Media_DL_(Bytes)','Social_Media_UL_(Bytes)')\n",
    "frame['Google_Bytes']=sum_columns(data,'Google_DL_(Bytes)','Google_UL_(Bytes)')\n",
    "frame['Email_Bytes']=sum_columns(data,'Email_DL_(Bytes)','Email_UL_(Bytes)')\n",
    "frame['Youtube_Bytes']=sum_columns(data,'Youtube_DL_(Bytes)','Youtube_UL_(Bytes)')\n",
    "frame['Netflix_Bytes']=sum_columns(data,'Netflix_DL_(Bytes)','Netflix_UL_(Bytes)')\n",
    "frame['Gaming_Bytes']=sum_columns(data,'Gaming_DL_(Bytes)','Gaming_UL_(Bytes)')\n",
    "frame['Other_Bytes']=sum_columns(data,'Other_DL_(Bytes)','Other_UL_(Bytes)')\n",
    "frame['Total_Bytes']=sum_columns(data,'Total_DL_(Bytes)','Total_UL_(Bytes)')\n",
    "frame['Avg_RTT_ms']= avg_col(data,'Avg_RTT_DL_(ms)','Avg_RTT_UL_(ms)')\n",
    "frame['Avg_TCP_Bytes']=avg_col(data,'TCP_DL_Retrans._Vol_(Bytes)', 'TCP_UL_Retrans._Vol_(Bytes)')\n",
    "frame['Avg_Throughput_kbps']=avg_col(data,'Avg_Bearer_TP_DL_(kbps)', 'Avg_Bearer_TP_UL_(kbps)')\n",
    "\n",
    "frame.head()                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To make interpretaion of the data easier to digest, we convert the Bytes to Megabytes and miliseconds to seconds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert ms to s\n",
    "frame['Dur._(ms)'] =frame['Dur._(ms)']/1000\n",
    "\n",
    "#convert bytes to megabytes\n",
    "columns=['Social_Media_Bytes','Google_Bytes','Email_Bytes','Youtube_Bytes', 'Netflix_Bytes', 'Gaming_Bytes', 'Other_Bytes','Total_Bytes']\n",
    "for i in columns:\n",
    "    megabyte = 1*10e+5\n",
    "    frame[i]= frame[i]/megabyte\n",
    "\n",
    "frame.rename(columns={'Dur._(ms)':'Session_Duration_s','Social_Media_Bytes':'Social_Media_MB','Google_Bytes':'Google_MB',\n",
    "                     'Email_Bytes':'Email_MB','Youtube_Bytes':'Youtube_MB', 'Netflix_Bytes':'Netflix_MB', 'Gaming_Bytes':'Gaming_MB', 'Other_Bytes':'Other_MB','Total_Bytes':'Total_MB'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=frame.groupby(['MSISDN_Number','Handset_Type']).agg({'Bearer_Id':'count', 'Session_Duration_s':'sum', 'Total_MB':'sum','Social_Media_MB':'sum', 'Google_MB':'sum', 'Email_MB':'sum',\n",
    "       'Youtube_MB':'sum', 'Netflix_MB':'sum', 'Gaming_MB':'sum', 'Other_MB':'sum','Avg_RTT_ms':'mean','Avg_TCP_Bytes':'mean','Avg_Throughput_kbps':'mean'}).reset_index()\n",
    "\n",
    "df.rename(columns={'Bearer_Id':'No_of_xDRsessions'},inplace=True)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exploratory Data Analysis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Univariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_univariate(df,col1,col2):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    \n",
    "    plt.subplot(2,2,1)\n",
    "    plt.hist(df[col1],bins=20,color='#AEC6CF',edgecolor='blue',linewidth=0.5)\n",
    "    plt.title(f'Histogram of {col1}', size=14)\n",
    "    \n",
    "    plt.subplot(2,2,2)\n",
    "    plt.boxplot(df[col1])\n",
    "    plt.title(f'Boxplot of {col1}', size=14)\n",
    "    \n",
    "    plt.subplot(2,2,3)\n",
    "    plt.hist(df[col2],bins=20,color='#b39eb5',edgecolor='purple',linewidth=0.5)\n",
    "    plt.title(f'Histogram of {col2}', size=14)\n",
    "    \n",
    "    plt.subplot(2,2,4)\n",
    "    plt.boxplot(df[col2])\n",
    "    plt.title(f'Boxplot of {col2}', size=14)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the max values of each column, it is evident that the data has outliers, which will affect our EDA, hence\n",
    "  we have to find a way to deal with them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot before removing outliers\n",
    "plot_univariate(user,'Session_Duration_s','Total_MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = user.columns.to_list()\n",
    "del columns[:2]\n",
    "for i in columns:\n",
    "    user[i] = np.where(user[i] > user[i].quantile(0.95), user[i].median(),user[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user[['Netflix_MB', 'Gaming_MB', 'Other_MB']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_univariate(user,'Session_Duration_s','Total_MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_univariate(user,'Social_Media_MB','Email_MB',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_univariate(user,'Google_MB','Other_MB',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bivariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bivariate(df,col1,col2,col3,col4):\n",
    "    fig,ax = plt.subplots(2,2,figsize=(12,8),sharey=True)\n",
    "    \n",
    "    ax1=plt.subplot(221)\n",
    "    ax1.scatter(df[col1],df['Total_MB'],c='#AEC6CF',edgecolor='#AEC6CF',linewidth=1,alpha=0.8)\n",
    "    ax1.title.set_text(f'Scatter plot of {col1} against Total_MB')\n",
    "    \n",
    "    ax2=plt.subplot(222)\n",
    "    ax2.scatter(df[col2],df['Total_MB'],c='#AEC6CF',edgecolor='#AEC6CF',linewidth=1,alpha=0.8)\n",
    "    ax2.title.set_text(f'Scatter plot of {col2} against Total_MB')\n",
    "    \n",
    "    ax3=plt.subplot(223)\n",
    "    ax3.scatter(df[col3],df['Total_MB'],c='#AEC6CF',edgecolor='#AEC6CF',linewidth=1,alpha=0.8)\n",
    "    ax3.title.set_text(f'Scatter plot of {col3} against Total_MB')\n",
    "    \n",
    "    ax4=plt.subplot(224)\n",
    "    ax4.scatter(df[col4],df['Total_MB'],c='#AEC6CF',edgecolor='#AEC6CF',linewidth=1,alpha=0.8)\n",
    "    ax4.title.set_text(f'Scatter plot of {col4} against Total_MB')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bivariate(user.head(100),'Social_Media_MB','Google_MB','Email_MB', 'Youtube_MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bivariate(user.head(100),'Youtube_MB', 'Netflix_MB','Gaming_MB', 'Other_MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user['DecileRank']= pd.qcut(user['Session_Duration_s'],q = 5, labels = False)\n",
    "user.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user.groupby('DecileRank')['Total_MB'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=user[['Social_Media_MB', 'Google_MB', 'Email_MB','Youtube_MB', 'Netflix_MB', 'Gaming_MB', 'Other_MB']]\n",
    "corr = dataset.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Principal Component Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "columns = ['Social_Media_MB', 'Google_MB', 'Email_MB', 'Youtube_MB','Netflix_MB', 'Gaming_MB', 'Other_MB']\n",
    "dataset[columns]=StandardScaler().fit_transform(dataset[columns])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "transform=pca.fit_transform(dataset)\n",
    "dataset_transform=pd.DataFrame(transform,columns = ['Social_Media_Bytes', 'Google_Bytes', 'Email_Bytes', 'Youtube_Bytes','Netflix_Bytes', 'Gaming_Bytes', 'Other_Bytes'])\n",
    "dataset_transform.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task 2 - User Engagement analysis</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking the user’s engagement using the following engagement metrics: \n",
    "* sessions frequency \n",
    "* the duration of the session \n",
    "* the sessions total traffic (download and upload (bytes))\n",
    "\n",
    "The **user** dataframe had already aggregated the aforementioned metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregate the above metrics per customer id (MSISDN) and report the top 10 customers per engagement metric** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_metrics(data,col1,col2):\n",
    "    df=data[[col1,col2]]\n",
    "    dataf=df.sort_values(by=col1,ascending=False).head(10)\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_metrics(user,'No_of_xDRsessions','MSISDN_Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_metrics(user,'Session_Duration_s','MSISDN_Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_metrics(user,'Total_MB','MSISDN_Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-means clustering, to classify customers in three groups of engagement.**\n",
    "* Our engagement metrics have different variances i.e 0.535166, 76.961036 and 332.115321  respectively for variables 'No_of_xDRsessions', 'Session_Duration_s', 'Total_MB' \n",
    "* Therefore, we standardise each engagement metric before carrying out K-means\n",
    "* We use unlabelled data for this so we drop the MSISDN_Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.cluster import KMeans\n",
    "def kmeans_clusters(df,columns,n,title):\n",
    "    kmeans=KMeans(n_clusters=n)\n",
    "    data=df.copy()\n",
    "    data[columns]=StandardScaler().fit_transform(data[columns])\n",
    "    cluster=kmeans.fit_predict(data[columns])\n",
    "    df[title]=cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = ['No_of_xDRsessions', 'Session_Duration_s', 'Total_MB']\n",
    "kmeans_clusters(df,columns,3,'engagement_clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engagement_metrics=df.groupby('engagement_clusters').agg({'No_of_xDRsessions':['min','mean','max','sum'],\n",
    "                                      'Session_Duration_s':['min','mean','max','sum'],\n",
    "                                      'Total_MB':['min','mean','max','sum']})\n",
    "engagement_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregate user total traffic per application and derive the top 10 most engaged users per application**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_metrics(user,'Social_Media_MB','MSISDN_Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_metrics(user,'Google_MB','MSISDN_Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_metrics(user,'Email_MB','MSISDN_Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_metrics(user,'Youtube_MB','MSISDN_Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_metrics(user,'Netflix_MB','MSISDN_Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_metrics(user,'Gaming_MB','MSISDN_Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_metrics(user,'Other_MB','MSISDN_Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the top 3 most used applications using appropriate charts.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns=['Social_Media_MB', 'Google_MB', 'Email_MB', 'Youtube_MB', 'Netflix_MB','Gaming_MB', 'Other_MB']\n",
    "apps=user[columns].sum().sort_values(ascending=False).nlargest(3)\n",
    "\n",
    "plt.bar(apps.index,apps,color='#b39eb5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using k-means clustering algorithm, group users in k engagement clusters based on the engagement metrics using the elbow method**\n",
    "\n",
    "We can choose 4 as the number of clusters, as that's the value of k at the \"elbow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining k\n",
    "#wcss is the sum of squared distance between each point\n",
    "customer=user[['No_of_xDRsessions', 'Session_Duration_s', 'Total_MB']]\n",
    "columns = ['No_of_xDRsessions', 'Session_Duration_s', 'Total_MB']\n",
    "customer[columns]=StandardScaler().fit_transform(customer[columns])\n",
    "\n",
    "wcss_list=[]\n",
    "for i in range(1,5):\n",
    "    kmeans=KMeans()\n",
    "    kmeans.fit(customer[columns])\n",
    "    wcss_iter=kmeans.inertia_\n",
    "    wcss_list.append(wcss_iter)\n",
    "\n",
    "plt.plot(range(1,5),wcss_list)\n",
    "plt.xlabel('#Clusters(K)')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Grouping users by K-Means Clustering(Elbow Method)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans=KMeans(n_clusters=3)\n",
    "cluster=kmeans.fit_predict(customer[columns])\n",
    "customer['cluster']=cluster\n",
    "user_clusters=customer.groupby('cluster').agg({'No_of_xDRsessions':['min','mean','max','sum'],'Session_Duration_s':['min','mean','max','sum'],\n",
    "                                      'Total_MB':['min','mean','max','sum']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task 3 - Experience Analytics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirming that there are no outliers\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregate, per customer, the following information**\n",
    "* Average TCP retransmission\n",
    "* Average RTT\n",
    "* Handset type\n",
    "* Average throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience=frame.copy()\n",
    "experience=experience.groupby(['MSISDN_Number','Handset_Type']).agg({'Avg_RTT_ms':'mean','Avg_TCP_Bytes':'mean','Avg_Throughput_kbps':'mean'}).reset_index()\n",
    "experience.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute & list 10 of the top, bottom and most frequent:**\n",
    "* TCP values in the dataset. \n",
    "* RTT values in the dataset.\n",
    "* Throughput values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_values(data,col1,asc):\n",
    "    df=data[[col1]]\n",
    "    dataf=df.sort_values(by=col1,ascending=asc).head(10)\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_values(experience,'Avg_RTT_ms',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_values(experience,'Avg_TCP_Bytes',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_values(experience,'Avg_Throughput_kbps',False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottom 10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_values(experience,'Avg_RTT_ms',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_values(experience,'Avg_TCP_Bytes',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_values(experience,'Avg_Throughput_kbps',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequently occurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_counts(data,col):\n",
    "    df=data[[col]]\n",
    "    dataf=df.value_counts().head(10)\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_counts(experience,'Avg_RTT_ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_counts(experience,'Avg_TCP_Bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_counts(experience,'Avg_Throughput_kbps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handset=experience.groupby('Handset_Type').agg({'Avg_Throughput_kbps':'mean','Avg_TCP_Bytes':'mean'}).reset_index()\n",
    "handset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The distribution of the average throughput  per handset type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_handset(data,col1,col2,n):\n",
    "    handsets=data.sort_values(by=col1,ascending=False)\n",
    "\n",
    "    #plot\n",
    "    plt.figure(figsize=(12,6))\n",
    "    ax=sns.barplot(handsets[col2][:n],handsets[col1][:n],palette='PuBuGn',dodge=False)\n",
    "    ax.set_xticklabels(handsets[col2][:n],rotation=80)\n",
    "    plt.title(f'Distribution of the top {n} {col1} per {col2}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_handset(handset,'Avg_Throughput_kbps','Handset_Type',20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The distribution of the average TCP retransmission per handset type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_handset(handset,'Avg_TCP_Bytes','Handset_Type',20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the experience metrics above, perform a k-means clustering (where k = 3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the k-means function we created\n",
    "columns=['Avg_RTT_ms','Avg_Throughput_kbps', 'Avg_TCP_Bytes']\n",
    "kmeans_clusters(df,columns,3,'experience_clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_metrics=df.groupby('experience_clusters').agg({'Avg_RTT_ms':'mean','Avg_Throughput_kbps':'mean','Avg_TCP_Bytes':'mean'})\n",
    "experience_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engagement_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task 4 - Satisfaction Analysis</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate:\n",
    "* engagement score to each user. Consider the engagement score as the Euclidean distance between the user data point & the less engaged cluster (use the first clustering for this) \n",
    "* experience score to each user. Consider the experience score as the Euclidean distance between the user data point & the worst experience’s cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engagement_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['satisfaction_score']= avg_col(df,'engagement_clusters','experience_clusters')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#satisfaction score ranges from 0-3\n",
    "sort_metrics(df,'satisfaction_score','MSISDN_Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a regression model of your choice to predict the satisfaction score of a\n",
    "customer**\n",
    "\n",
    "Multivariate Linear Regression Model because we have multiple explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.get_dummies(data=df,columns=['Handset_Type'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X= df.drop(['satisfaction_score','MSISDN_Number'],axis=1)\n",
    "y=df['satisfaction_score']\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
